Suppose $v_1, \dots, v_m$ is linearly independent in $V$ and $w \in V$. Prove that if $v_1 + w, \dots, v_m + w$ is linearly dependent, then $w \in \text{span}(v_1,\dots,v_m)$.

---

Suppose $v_1+w\dots,v_m+w$ is linearly dependent, then
$$
a_1(v_1+w) + \dots + a_m(v_m+w) = 0
$$
With some $a_j \ne 0$. Distribute and move the $w$'s to one side
$$
a_1v_1 + \dots + a_mv_m = -(a_1+\dots+a_m)w
$$
Since the $v$'s are linearly independent, and some $a_j \ne 0$ we must have $a_1v_1 + \dots + a_mv_m \ne 0$. Therefor $-(a_1+\dots+a_m)w \ne 0$ which allows us to divide by the constant term to get
$$
w = b_1v_1 + \dots + b_m v_m 
$$
For $b_k = -a_k/(a_1 + \dots + a_m)$. Thus $w \in \text{span}(v_1,\dots,v_m)$.

