Suppose $V$ and $W$ are finite-dimensional and that $U$ is a subspace of $V$.
Prove that there exists $T \in \mathcal L(V, W)$ such that $\text{null }T = U$ if and only if $\dim U \ge \dim V - \dim W$.

---

Let $v_1,\dots,v_r$ be a basis for $U$ and define $Tv_j = 0$ for all $1 \le j \le r$, we now have $U = \text{null }T$ and would like to finish definining $T$ without adding anything to the nullspace.
Extend $v_1,\dots,v_r$ to a basis $v_1,\dots,v_n$ of $V$ using 2.33 and let $w_1,\dots,w_m$ be a basis of $W$.

I'd like to define $Tv_{j+r} = w_j$ for the rest of the $v_j$'s, but this requires $m \ge n-r$ so that $W$ has room for $n-r$ independent vectors. Rearranging our condition gives $r \ge n-m$ which is just
$$
\dim U \ge \dim V - \dim W
$$
This completes the forward direction.

To see $\text{null }T = U$ is impossible when $\dim U < \dim V - \dim W$ we simply apply [[3.22]]
$$
\begin{aligned}
\dim V
&= \dim \text{null } T + \dim \text{range }T \\
&= \dim U + \dim \text{range }T \\
&< \dim V - \dim W + \dim \text{range }T
\end{aligned}
$$
Which implies $\dim W < \dim \text{range }T$ which is impossible since $\text{range }T$ is a subspace of $W$.
This completes the backward direction.